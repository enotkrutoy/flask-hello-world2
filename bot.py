import re
import aiohttp
import logging
import os
from telegram import Update, ParseMode
from telegram.ext import (
    ApplicationBuilder,
    ContextTypes,
    CommandHandler,
    MessageHandler,
    filters,
)
from dotenv import load_dotenv
import speech_recognition as sr
from io import BytesIO

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω—ã –∏ –∫–ª—é—á–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
HF_API_KEY = os.getenv("HF_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–π
if not HF_API_KEY or not TELEGRAM_BOT_TOKEN:
    logger.error("–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
    exit(1)

# Hugging Face URL
HF_API_URL = "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions"
DEFAULT_SYSTEM_PROMPT = "–ø–æ–º–æ—â–Ω–∏–∫"

def escape_markdown_v2(text):
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –±–ª–æ–∫–∞—Ö –∫–æ–¥–∞ MarkdownV2.
    """
    escape_chars = r"_*[]()~`>#+-=|{}.!$&@"
    return re.sub(f"([{re.escape(escape_chars)}])", r"\\\1", text)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã. –ù–∞–ø–∏—à–∏—Ç–µ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    if not user_message:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return
    await update.message.reply_text("üëÄ –î—É–º–∞—é... üêáüêáüêá")
    system_prompt = context.user_data.get("system_prompt", DEFAULT_SYSTEM_PROMPT)
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
        "temperature": 0.5,
        "max_tokens": 2048,
        "top_p": 0.7,
        "stream": False,
    }
    try:
        data = await fetch_with_retries(HF_API_URL, headers, payload)
        choices = data.get("choices")
        if not choices or "message" not in choices[0]:
            await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç API: {data}")
            return
        reply = choices[0].get("message", {}).get("content", "")
        if not reply:
            await update.message.reply_text("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ —Å–º–æ–≥ –ø—Ä–∏–¥—É–º–∞—Ç—å –æ—Ç–≤–µ—Ç–∞.")
            return
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        if len(reply) > 4096:
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–¥–µ–ª–∏–º –µ–≥–æ –Ω–∞ —á–∞—Å—Ç–∏
            chunks = [reply[i:i+4096] for i in range(0, len(reply), 4096)]
            for chunk in chunks:
                await update.message.reply_text(chunk)
        else:
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ –¥–ª–∏–Ω–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ —Ü–µ–ª–∏–∫–æ–º
            if "```" in reply:
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã Markdown –≤ —Ç–µ–∫—Å—Ç–µ
                escaped_reply = escape_markdown_v2(reply)
                code_block = f"```\n{escaped_reply}\n```"
                await update.message.reply_text(code_block, parse_mode="MarkdownV2")
            else:
                await update.message.reply_text(reply)
    except aiohttp.ClientError as e:
        logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {e}")
        await update.message.reply_text(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {e}")
    except Exception as e:
        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        await update.message.reply_text(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

async def fetch_with_retries(url, headers, json, retries=3):
    for attempt in range(retries):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=json) as response:
                    response.raise_for_status()
                    return await response.json()
        except aiohttp.ClientError as e:
            if attempt == retries - 1:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                raise
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä—è—é...")

async def clear_history(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")

async def view_history(update: Update, context: ContextTypes.DEFAULT_TYPE):
    history = context.user_data.get("history", [])
    if not history:
        await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø—É—Å—Ç–∞.")
    else:
        history_text = "\n".join(history)
        await update.message.reply_text(f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{history_text}")

async def set_system_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç.")
        return
    system_prompt = " ".join(context.args)
    context.user_data["system_prompt"] = system_prompt
    await update.message.reply_text(f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {system_prompt}")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    document = update.message.document
    if not document or document.mime_type != "text/plain":
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª.")
        return
    file = await document.get_file()
    file_content = await file.download_as_string()
    await update.message.reply_text(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞:\n{file_content}")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice = update.message.voice
    if not voice:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return
    file = await voice.get_file()
    file_content = await file.download_as_bytearray()
    recognizer = sr.Recognizer()
    audio_file = sr.AudioFile(BytesIO(file_content))
    with audio_file as source:
        audio_data = recognizer.record(source)
    text = recognizer.recognize_google(audio_data, language="ru-RU")
    await update.message.reply_text(f"–¢–µ–∫—Å—Ç: {text}")

if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(CommandHandler("clear", clear_history))
    app.add_handler(CommandHandler("history", view_history))
    app.add_handler(CommandHandler("set_system_prompt", set_system_prompt))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    app.run_polling()
